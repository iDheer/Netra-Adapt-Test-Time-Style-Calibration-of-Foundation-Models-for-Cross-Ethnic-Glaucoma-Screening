# Netra-Adapt: Test-Time Style Calibration of Foundation Models for Cross-Ethnic Glaucoma Screening

**Source-Free Domain Adaptation for Cross-Ethnic Medical Imaging**

Netra-Adapt adapts foundation vision models trained on Western fundus images (AIROGS) to work on Indian eyes (Ch√°k·π£u) **without any labeled target data**, using a novel MixEnt-Adapt algorithm for test-time style calibration.

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## üéØ Key Features

- ‚úÖ **Source-Free Domain Adaptation**: No labeled target data needed
- ‚úÖ **Foundation Model**: DINOv3 ViT-L/16 (state-of-the-art)
- ‚úÖ **MixEnt-Adapt**: Entropy-based style injection + Information Maximization
- ‚úÖ **Cross-Ethnic**: Western (AIROGS) ‚Üí Indian (Ch√°k·π£u) fundus images
- ‚úÖ **Early Stopping**: Automatic training optimization
- ‚úÖ **Comprehensive Logging**: Tracks all metrics, curves, visualizations
- ‚úÖ **Research Ready**: 7 metrics + ROC curves + statistical tests

---

## üìä Experimental Setup

**5 Baseline Comparisons:**

1. **Pretrained ‚Üí Ch√°k·π£u**: Vanilla DINOv3 (zero-shot)
2. **AIROGS ‚Üí AIROGS**: Source model sanity check
3. **AIROGS ‚Üí Ch√°k·π£u**: Source-only (no adaptation)
4. **Ch√°k·π£u ‚Üí Ch√°k·π£u**: Oracle upper bound (fully supervised)
5. **AIROGS+Adapt ‚Üí Ch√°k·π£u**: **Netra-Adapt** (our method)

**Datasets:**
- **AIROGS V2**: ~4,000 Western fundus images (80/20 train/test split)
- **Ch√°k·π£u**: 1,345 Indian fundus images (1,009 train / 336 test)

**Metrics:**
- AUROC, Sensitivity, Specificity, Precision, F1-Score, Accuracy, Sensitivity@95% Specificity

---

## üóÇÔ∏è Project Structure

```
Netra-Adapt/
‚îú‚îÄ‚îÄ Netra_Adapt/                        # Main codebase
‚îÇ   ‚îú‚îÄ‚îÄ models.py                       # DINOv3 ViT-L/16 model
‚îÇ   ‚îú‚îÄ‚îÄ dataset_loader.py               # Dataset handling
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                        # Helper functions
‚îÇ   ‚îú‚îÄ‚îÄ prepare_data.py                 # Generate train/test CSVs
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ train_source.py                 # Phase A: AIROGS training
‚îÇ   ‚îú‚îÄ‚îÄ train_oracle.py                 # Phase B: Oracle baseline
‚îÇ   ‚îú‚îÄ‚îÄ adapt_target.py                 # Phase C: MixEnt-Adapt SFDA
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py                     # Phase D: Evaluation
‚îÇ   ‚îú‚îÄ‚îÄ advanced_analysis.py            # Phase E: Interpretability
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ training_logger.py              # Comprehensive logging system
‚îÇ   ‚îú‚îÄ‚îÄ run_full_pipeline.py            # Automated pipeline runner
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ setup_with_download.sh          # Vast.ai setup script
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies
‚îÇ   
‚îÇ
‚îú‚îÄ‚îÄ data/                               # Datasets (downloaded)
‚îÇ   ‚îú‚îÄ‚îÄ AIROGS_V2/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ RG/                         # Referable glaucoma
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ NRG/                        # No referable glaucoma
‚îÇ   ‚îî‚îÄ‚îÄ chaksu_dataset/
‚îÇ       ‚îú‚îÄ‚îÄ Train/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ Bosch/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ Forus/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ Remidio/
‚îÇ       ‚îî‚îÄ‚îÄ Test/
‚îÇ
‚îú‚îÄ‚îÄ results/                            # Trained models
‚îÇ   ‚îú‚îÄ‚îÄ Source_AIROGS/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model.pth
‚îÇ   ‚îú‚îÄ‚îÄ Oracle_Chaksu/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ best_oracle.pth
‚îÇ   ‚îî‚îÄ‚îÄ Adapted_Chaksu/
‚îÇ       ‚îî‚îÄ‚îÄ adapted_model.pth
‚îÇ
‚îî‚îÄ‚îÄ logs/                               # Experiment logs
    ‚îî‚îÄ‚îÄ run_YYYY-MM-DD_HH-MM-SS/
        ‚îú‚îÄ‚îÄ experiment_log.txt
        ‚îú‚îÄ‚îÄ metadata.json
        ‚îú‚îÄ‚îÄ EXPERIMENT_SUMMARY.md
        ‚îú‚îÄ‚îÄ 01_source_training/
        ‚îú‚îÄ‚îÄ 02_oracle_training/
        ‚îú‚îÄ‚îÄ 03_adaptation/
        ‚îú‚îÄ‚îÄ 04_evaluation/
        ‚îî‚îÄ‚îÄ 05_advanced_analysis/
```

---

## üöÄ Quick Start (Vast.ai)

### 1Ô∏è‚É£ Launch Vast.ai Instance

**Recommended Specs:**
- GPU: RTX 5090
- VRAM: ‚â•24GB
- Storage: ‚â•256 (datasets are large)
- CUDA: 12.8 or above

**Search Filter:**
```
```

### 2Ô∏è‚É£ Connect to Instance

```bash
# SSH into your Vast.ai instance
ssh -p YOUR_PORT root@YOUR_IP

# Verify GPU
nvidia-smi
```

### 3Ô∏è‚É£ Clone Repository

```bash
cd /workspace
git clone https://github.com/iDheer/Netra-Adapt-Test-Time-Style-Calibration-of-Foundation-Models-for-Cross-Ethnic-Glaucoma-Screening.git
cd Netra-Adapt-Test-Time-Style-Calibration-of-Foundation-Models-for-Cross-Ethnic-Glaucoma-Screening/Netra_Adapt
```

### 4Ô∏è‚É£ Run Setup Script (Installs Everything!)

**This ONE script does EVERYTHING:**
- ‚úÖ Installs all system libraries (libgl1, libglib2.0, unzip, wget, curl)
- ‚úÖ Installs PyTorch with CUDA 12.1 support
- ‚úÖ Installs all Python dependencies (timm, transformers, scikit-learn, pandas, numpy, opencv, matplotlib, seaborn, scipy, umap-learn, tqdm)
- ‚úÖ Downloads AIROGS V2 dataset (~8GB)
- ‚úÖ Downloads Ch√°k·π£u dataset (~2GB)
- ‚úÖ Sets up directory structure
- ‚úÖ Verifies datasets

```bash
bash setup_with_download.sh
```

**Expected Time:** ~20 minutes (depending on internet speed)

**You don't need to run `pip install -r requirements.txt` separately!**

### 5Ô∏è‚É£ Prepare Data

Generate train/test CSV files:

```bash
python prepare_data.py
```

**Output:**
- `data/processed_csvs/airogs_train.csv` (80% of AIROGS)
- `data/processed_csvs/airogs_test.csv` (20% of AIROGS)
- `data/processed_csvs/chaksu_train_labeled.csv` (1,009 images)
- `data/processed_csvs/chaksu_test_labeled.csv` (336 images)
- `data/processed_csvs/chaksu_train_unlabeled.csv` (for SFDA)

### 6Ô∏è‚É£ Run Full Pipeline

**Option A: Automated (Recommended)**

```bash
python run_full_pipeline.py
```

This runs all 5 phases sequentially and generates complete logs.

**Option B: Manual (Step-by-Step)**

```bash
# Phase A: Train on AIROGS (Western eyes)
python train_source.py          # ~2-3 hours, early stops ~30-35 epochs

# Phase B: Train Oracle (Upper bound)
python train_oracle.py          # ~1-2 hours, early stops ~35-40 epochs

# Phase C: Adapt to Ch√°k·π£u (SFDA)
python adapt_target.py          # ~45-60 minutes, early stops ~15-18 epochs

# Phase D: Evaluate All Models
python evaluate.py              # ~10 minutes

# Phase E: Advanced Analysis (Optional)
python advanced_analysis.py --all  # ~20 minutes
```

**Expected Total Time:** ~4-5 hours (with early stopping)

---

## üìà Output & Results

### Training Logs

All experiments are logged to timestamped directories:

```
logs/run_2026-02-02_14-30-45/
‚îú‚îÄ‚îÄ experiment_log.txt              # Human-readable log
‚îú‚îÄ‚îÄ metadata.json                   # Machine-readable metadata
‚îú‚îÄ‚îÄ EXPERIMENT_SUMMARY.md           # Final summary report
‚îú‚îÄ‚îÄ 01_source_training/
‚îÇ   ‚îú‚îÄ‚îÄ hyperparameters.json
‚îÇ   ‚îú‚îÄ‚îÄ epoch_metrics.csv           # Loss, accuracy per epoch
‚îÇ   ‚îú‚îÄ‚îÄ loss_curve.png              # Training curve
‚îÇ   ‚îî‚îÄ‚îÄ additional_metrics.png
‚îú‚îÄ‚îÄ 02_oracle_training/
‚îÇ   ‚îî‚îÄ‚îÄ (same structure)
‚îú‚îÄ‚îÄ 03_adaptation/
‚îÇ   ‚îî‚îÄ‚îÄ epoch_metrics.csv           # Includes L_ent, L_div
‚îú‚îÄ‚îÄ 04_evaluation/
‚îÇ   ‚îú‚îÄ‚îÄ Pretrained_to_Chaksu_metrics.json
‚îÇ   ‚îú‚îÄ‚îÄ AIROGS_to_Chaksu_metrics.json
‚îÇ   ‚îú‚îÄ‚îÄ Chaksu_to_Chaksu_metrics.json
‚îÇ   ‚îú‚îÄ‚îÄ AIROGS+Adapt_to_Chaksu_metrics.json
‚îÇ   ‚îú‚îÄ‚îÄ roc_curves.png              # All models on one plot
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrices.png      # 2x2 grid
‚îÇ   ‚îú‚îÄ‚îÄ metrics_comparison.png      # Bar chart
‚îÇ   ‚îú‚îÄ‚îÄ results.csv                 # Table of metrics
‚îÇ   ‚îî‚îÄ‚îÄ results_latex.txt           # LaTeX table
‚îî‚îÄ‚îÄ 05_advanced_analysis/
    ‚îú‚îÄ‚îÄ tsne_features.png           # Feature space visualization
    ‚îú‚îÄ‚îÄ umap_features.png
    ‚îú‚îÄ‚îÄ gradcam_samples.png         # Attention maps
    ‚îú‚îÄ‚îÄ calibration_curves.png      # Model calibration
    ‚îú‚îÄ‚îÄ per_camera_analysis.png     # Camera-specific performance
    ‚îî‚îÄ‚îÄ statistical_tests.txt       # McNemar's test results
```

### View Results

```bash
# View summary report
cat logs/run_*/EXPERIMENT_SUMMARY.md

# View evaluation metrics
cat results/evaluation/results.csv

# Copy results to local machine
scp -P YOUR_PORT root@YOUR_IP:/workspace/Netra-Adapt/.../logs/ ./local_logs/
```

---

## üî¨ Algorithm: MixEnt-Adapt

**Source-Free Domain Adaptation via Entropy-Guided Style Injection**

```
1. Partition batch by entropy:
   - High confidence samples (low entropy)
   - Low confidence samples (high entropy)

2. Style injection via AdaIN:
   - Inject statistics from confident ‚Üí uncertain
   - Calibrates style while preserving semantics

3. Information Maximization Loss:
   L_SFDA = L_ent - Œª * L_div
   
   - L_ent: Entropy minimization (decisive predictions)
   - L_div: Diversity maximization (prevents collapse)
   - Œª = 1.0 (balance parameter)
```

**Key Advantages:**
- ‚úÖ No target labels needed (source-free)
- ‚úÖ No source data needed during adaptation
- ‚úÖ Preserves discriminative features
- ‚úÖ Prevents mode collapse

---

## üéì Evaluation Metrics

**Standard Clinical Metrics:**

| Metric | Description | Clinical Relevance |
|--------|-------------|-------------------|
| **AUROC** | Area Under ROC Curve | Overall discrimination ability |
| **Sensitivity** | True Positive Rate | Catching glaucoma cases |
| **Specificity** | True Negative Rate | Avoiding false alarms |
| **Precision** | Positive Predictive Value | Accuracy of positive diagnoses |
| **F1-Score** | Harmonic mean | Balanced metric |
| **Accuracy** | Overall correctness | General performance |
| **Sens@95** | Sensitivity at 95% Specificity | Clinically relevant tradeoff |

**Statistical Tests:**
- McNemar's test for paired predictions
- p-values for significance testing

---

## üì¶ Requirements

### Hardware
- GPU: ‚â•24GB VRAM (RTX 4090 / A6000 / A100)
- RAM: ‚â•32GB
- Storage: ‚â•1TB (datasets + models + logs)
- CUDA: 12.1+

### Software
```txt
Python >= 3.10
PyTorch >= 2.0
transformers >= 4.30.0
timm >= 0.9.0
scikit-learn >= 1.3.0
pandas >= 2.0.0
numpy >= 1.24.0
opencv-python >= 4.8.0
matplotlib >= 3.7.0
seaborn >= 0.12.0
scipy >= 1.11.0
umap-learn >= 0.5.0
tqdm >= 4.65.0
```

**Install all:**
```bash
pip install -r requirements.txt
```

---

## üõ†Ô∏è Configuration

### Hyperparameters

**train_source.py (AIROGS)**
```python
BATCH_SIZE = 32
MAX_EPOCHS = 50
EARLY_STOP_PATIENCE = 5
LR_BACKBONE = 1e-5
LR_HEAD = 1e-3
```

**train_oracle.py (Oracle)**
```python
BATCH_SIZE = 24          # Smaller for small dataset
MAX_EPOCHS = 60
EARLY_STOP_PATIENCE = 8  # More patience for small dataset
LR_BACKBONE = 1e-5
LR_HEAD = 1e-3
```

**adapt_target.py (SFDA)**
```python
BATCH_SIZE = 32
MAX_EPOCHS = 25          # Faster adaptation
EARLY_STOP_PATIENCE = 5
LR_BACKBONE = 1e-6       # Lower to preserve source knowledge
LR_HEAD = 1e-4
LAMBDA_DIV = 1.0         # Diversity weight
```

### Paths (Automatically set by setup script)

```python
# Data paths
DATA_DIR = "/workspace/data"
CSV_DIR = "/workspace/data/processed_csvs"

# Model paths
SAVE_DIR = "/workspace/results"

# Log paths
LOG_DIR = "logs"
```

---

## üìä Expected Results

**Typical Performance (AUROC on Ch√°k·π£u Test Set):**

| Model | AUROC | Description |
|-------|-------|-------------|
| Pretrained ‚Üí Ch√°k·π£u | ~0.75 | Vanilla DINOv3 (zero-shot) |
| AIROGS ‚Üí Ch√°k·π£u | ~0.82 | Source-only (no adaptation) |
| **AIROGS+Adapt ‚Üí Ch√°k·π£u** | **~0.88** | **Netra-Adapt (our method)** |
| Ch√°k·π£u ‚Üí Ch√°k·π£u | ~0.92 | Oracle (upper bound) |

**Key Observations:**
- ‚úÖ Netra-Adapt bridges ~60% of the domain gap
- ‚úÖ Significant improvement over source-only
- ‚úÖ Approaches oracle performance without labels

---

## üêõ Troubleshooting

### CUDA Out of Memory
```bash
# Reduce batch size in config
BATCH_SIZE = 16  # Instead of 32
```

### Dataset Not Found
```bash
# Re-run data preparation
python prepare_data.py
```

### Missing Dependencies
```bash
# Reinstall requirements
pip install -r requirements.txt --force-reinstall
```

### HuggingFace Model Access
```bash
# Login to HuggingFace (for DINOv3)
huggingface-cli login
# Enter your token when prompted
```

### Disk Space Issues
```bash
# Check available space
df -h

# Clean up old logs
rm -rf logs/run_old_*
```

---

## üìö Documentation

- **[LOGGING_QUICK_REFERENCE.md](Netra_Adapt/LOGGING_QUICK_REFERENCE.md)** - Logging system guide
- **[EARLY_STOPPING_SUMMARY.md](Netra_Adapt/EARLY_STOPPING_SUMMARY.md)** - Early stopping details
- **[COMPLETE_EXPERIMENTAL_SETUP.md](Netra_Adapt/COMPLETE_EXPERIMENTAL_SETUP.md)** - Full experimental protocol
- **[LOGGING_GUIDE.md](Netra_Adapt/LOGGING_GUIDE.md)** - Comprehensive logging documentation

---

## üîó Citation

If you use this code in your research, please cite:

```bibtex
@article{netra-adapt-2026,
  title={Netra-Adapt: Test-Time Style Calibration of Foundation Models for Cross-Ethnic Glaucoma Screening},
  author={Your Name},
  journal={arXiv preprint},
  year={2026}
}
```

---

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üôè Acknowledgments

- **DINOv3**: Meta AI Research
- **AIROGS Dataset**: Grand Challenge
- **Ch√°k·π£u Dataset**: Indian fundus image consortium
- **Vast.ai**: GPU cloud compute

---

## üìß Contact

For questions or issues:
- Open an issue on GitHub
- Contact: [your-email@example.com]

---

## üö¶ Quick Command Reference

```bash
# Setup
bash setup_with_download.sh
python prepare_data.py

# Run pipeline
python run_full_pipeline.py

# Or run individually
python train_source.py
python train_oracle.py
python adapt_target.py
python evaluate.py
python advanced_analysis.py --all

# View results
cat logs/run_*/EXPERIMENT_SUMMARY.md
```

---

**Ready to run? Start with `bash setup_with_download.sh`! üöÄ**
